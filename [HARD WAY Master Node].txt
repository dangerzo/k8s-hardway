[HARD WAY Master Node]

PREINSTALL 

hosts IP 등록





yum install -y expect
service firewalld stop
systemctl disable firewalld
iptables -L 
yum install -y wget
yum install -y bind-utils




MultiMaster 를 위한 haproxy 구성

yum install -y haproxy
service firewalld stop
systemctl disable firewalld
iptables -L 


vi /etc/haproxy/haproxy.cfg

### Kubernetes Multi Master Proxy Config ###

frontend K8S-Master
       bind 192.168.1.47:8080
       default_backend K8S-Master-Nodes

backend K8S-Master-Nodes
       mode        http
       balance     roundrobin
       server      master1 192.168.1.26:8080 check
       server      master2 192.168.1.42:8080 check
       server      master3 192.168.1.44:8080 check

service haproxy start
systemctl enable haproxy






[kubernetes-the-hard-way]

https://github.com/jmyung/kubernetes-the-hard-way-modified/blob/master/docs/prerequisites.md
https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/02-client-tools.md
https://github.com/kelseyhightower/kubernetes-the-hard-way
https://developer.ibm.com/recipes/tutorials/installing-kubernetes-the-hard-way/
https://github.com/Praqma/LearnKubernetes/blob/master/kamran/Kubernetes-The-Hard-Way-on-BareMetal.md
https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/04-certificate-authority.md


Kubernetes Hard Way 구성하기


1. Kubernetes 인증서 생성

1-1 CA 인증서




https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/02-client-tools.md

### PKI infrastructure 및 TLS certificates 를 generate 하는 command

yum install -y wget

wget \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssl \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssljson

chmod +x cfssl cfssljson
sudo mv cfssl cfssljson /usr/local/bin/

### cfssl 및 cfssljson 의 버전은 1.4.1 이상 버전이 설치되어야 한다. (버전 검증)
cfssl version
cfssljson --version

### kubectl 설치
wget https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/

kubectl version --client

sudo hostnamectl set-hostname master01
sudo hostnamectl set-hostname worker01

### 서버 기본구성
master01
master02
master03
worker01
worker02
worker03

### 인증서 구성
cloudflare 의 PKI toolkit 인 cfssl 로 인증서 작업진행

### 작업대상
etcd, kube-apiserver, kube-controller-manager, kube-scheduler, kubelet, and kube-proxy

Certificate Authority (CA) 구성
TLS Generate 를 할수있는 CA 를 구성한다.
CA 는 CA configuration file, certificate, private key 이렇게 3가지 

{

cat > ca-config.json <<EOF
{
  "signing": {
    "default": {
      "expiry": "8760h"
    },
    "profiles": {
      "kubernetes": {
        "usages": ["signing", "key encipherment", "server auth", "client auth"],
        "expiry": "8760h"
      }
    }
  }
}
EOF

cat > ca-csr.json <<EOF
{
  "CN": "Kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "Kubernetes",
      "OU": "CA",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert -initca ca-csr.json | cfssljson -bare ca

}



{
> 
> cat > ca-config.json <<EOF
> {
>   "signing": {
>     "default": {
>       "expiry": "8760h"
>     },
>     "profiles": {
>       "kubernetes": {
>         "usages": ["signing", "key encipherment", "server auth", "client auth"],
>         "expiry": "8760h"
>       }
>     }
>   }
> }
> EOF
> 
> cat > ca-csr.json <<EOF
> {
>   "CN": "Kubernetes",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "Kubernetes",
>       "OU": "CA",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert -initca ca-csr.json | cfssljson -bare ca
> 
> }
2020/11/19 17:07:11 [INFO] generating a new CA key and certificate from CSR
2020/11/19 17:07:11 [INFO] generate received request
2020/11/19 17:07:11 [INFO] received CSR
2020/11/19 17:07:11 [INFO] generating key: rsa-2048
2020/11/19 17:07:11 [INFO] encoded CSR
2020/11/19 17:07:11 [INFO] signed certificate with serial number 86399257728757429273473382034589609742683330020


[root@localhost ~]# ll
total 24
-rw-------. 1 root root 1257 Nov 13 16:54 anaconda-ks.cfg
-rw-r--r--. 1 root root  232 Nov 19 17:07 ca-config.json
-rw-r--r--. 1 root root 1005 Nov 19 17:07 ca.csr
-rw-r--r--. 1 root root  211 Nov 19 17:07 ca-csr.json
-rw-------. 1 root root 1679 Nov 19 17:07 ca-key.pem
-rw-r--r--. 1 root root 1318 Nov 19 17:07 ca.pem



### Client and Server Certificates
Kubernetes 구성 요소에 대한 클라이언트 및 서버 인증서와 Kubernetes 관리자 사용자에 대한 클라이언트 인증서를 생성

The Admin Client Certificate

{

cat > admin-csr.json <<EOF
{
  "CN": "admin",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:masters",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  admin-csr.json | cfssljson -bare admin

}


{
> 
> cat > admin-csr.json <<EOF
> {
>   "CN": "admin",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "system:masters",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -profile=kubernetes \
>   admin-csr.json | cfssljson -bare admin
> 
> }
2020/11/19 17:11:54 [INFO] generate received request
2020/11/19 17:11:54 [INFO] received CSR
2020/11/19 17:11:54 [INFO] generating key: rsa-2048
2020/11/19 17:11:54 [INFO] encoded CSR
2020/11/19 17:11:54 [INFO] signed certificate with serial number 597268315560805519045788725736806090307956513923
2020/11/19 17:11:54 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").

[root@localhost ~]# ll
total 40
-rw-r--r--. 1 root root 1033 Nov 19 17:11 admin.csr
-rw-r--r--. 1 root root  231 Nov 19 17:11 admin-csr.json
-rw-------. 1 root root 1675 Nov 19 17:11 admin-key.pem
-rw-r--r--. 1 root root 1428 Nov 19 17:11 admin.pem
-rw-------. 1 root root 1257 Nov 13 16:54 anaconda-ks.cfg
-rw-r--r--. 1 root root  232 Nov 19 17:07 ca-config.json
-rw-r--r--. 1 root root 1005 Nov 19 17:07 ca.csr
-rw-r--r--. 1 root root  211 Nov 19 17:07 ca-csr.json
-rw-------. 1 root root 1679 Nov 19 17:07 ca-key.pem
-rw-r--r--. 1 root root 1318 Nov 19 17:07 ca.pem



### The Kubelet Client Certificates
API requests made by Kubelets 을 처리하는 Node Authorizer 라는 특별한 인증모드가 존제함 "https://kubernetes.io/docs/reference/access-authn-authz/node/"
username 이 "system:node:<nodeName>" 인 "system:nodes" group 을 식별할수 있는 자격증명이 사용되어야 한다.
Node Authorizer 의 요구사항에 맞는 kubernetes worker node 에 대한 인증서 생성


EXTERNAL_IP=192.168.1.47 
INTERNAL_IP=("192.168.1.19" "192.168.1.23" "192.168.1.32")
instance=("worker01" "worker02" "worker03")

for ((i=0; i<3; i++)); do
cat > ${instance[i]}-csr.json <<EOF
{
  "CN": "system:node:${instance[i]}",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:nodes",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -hostname=${instance[i]},${INTERNAL_IP[i]},${EXTERNAL_IP} \
  -profile=kubernetes \
  ${instance[i]}-csr.json | cfssljson -bare ${instance[i]}
done

### The Controller Manager Client Certificate

{

cat > kube-controller-manager-csr.json <<EOF
{
  "CN": "system:kube-controller-manager",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:kube-controller-manager",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager

}


[root@localhost ~]# {
> 
> cat > kube-controller-manager-csr.json <<EOF
> {
>   "CN": "system:kube-controller-manager",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "system:kube-controller-manager",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -profile=kubernetes \
>   kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager
> 
> }
2020/11/19 18:13:42 [INFO] generate received request
2020/11/19 18:13:42 [INFO] received CSR
2020/11/19 18:13:42 [INFO] generating key: rsa-2048
2020/11/19 18:13:42 [INFO] encoded CSR
2020/11/19 18:13:42 [INFO] signed certificate with serial number 704134490551780953660555655006508506105669901102
2020/11/19 18:13:42 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").



### The Kube Proxy Client Certificate


{

cat > kube-proxy-csr.json <<EOF
{
  "CN": "system:kube-proxy",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:node-proxier",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  kube-proxy-csr.json | cfssljson -bare kube-proxy

}

[root@localhost ~]# {
> 
> cat > kube-proxy-csr.json <<EOF
> {
>   "CN": "system:kube-proxy",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "system:node-proxier",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -profile=kubernetes \
>   kube-proxy-csr.json | cfssljson -bare kube-proxy
> 
> }
2020/11/19 18:15:17 [INFO] generate received request
2020/11/19 18:15:17 [INFO] received CSR
2020/11/19 18:15:17 [INFO] generating key: rsa-2048
2020/11/19 18:15:17 [INFO] encoded CSR
2020/11/19 18:15:17 [INFO] signed certificate with serial number 2716018008416548120915164093655291430859687455
2020/11/19 18:15:17 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").



### The Scheduler Client Certificate
{

cat > kube-scheduler-csr.json <<EOF
{
  "CN": "system:kube-scheduler",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:kube-scheduler",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  kube-scheduler-csr.json | cfssljson -bare kube-scheduler

}

[root@localhost ~]# {
> 
> cat > kube-scheduler-csr.json <<EOF
> {
>   "CN": "system:kube-scheduler",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "system:kube-scheduler",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -profile=kubernetes \
>   kube-scheduler-csr.json | cfssljson -bare kube-scheduler
> 
> }
2020/11/19 18:16:35 [INFO] generate received request
2020/11/19 18:16:35 [INFO] received CSR
2020/11/19 18:16:35 [INFO] generating key: rsa-2048
2020/11/19 18:16:35 [INFO] encoded CSR
2020/11/19 18:16:35 [INFO] signed certificate with serial number 108317696401357277145267712734634864350850881100
2020/11/19 18:16:35 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").



### The Kubernetes API Server Certificate

{

EXTERNAL_IP=192.168.1.47 
MASTER_IP=("192.168.1.21" "192.168.1.55" "192.168.1.56")



KUBERNETES_HOSTNAMES=kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.svc.cluster.local

cat > kubernetes-csr.json <<EOF
{
  "CN": "kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "Kubernetes",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -hostname=10.32.0.1,${MASTER_IP[0]},${MASTER_IP[1]},${MASTER_IP[2]},127.0.0.1,${KUBERNETES_HOSTNAMES},${EXTERNAL_IP} \
  -profile=kubernetes \
  kubernetes-csr.json | cfssljson -bare kubernetes

}

[root@localhost ~]# {
> 
> KUBERNETES_HOSTNAMES=kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.svc.cluster.local
> 
> cat > kubernetes-csr.json <<EOF
> {
>   "CN": "kubernetes",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "Kubernetes",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -hostname=10.32.0.1,192.168.1.26,192.168.1.24,192.168.1.32,127.0.0.1,${KUBERNETES_HOSTNAMES} \
>   -profile=kubernetes \
>   kubernetes-csr.json | cfssljson -bare kubernetes
> 
> }
2020/11/19 19:33:45 [INFO] generate received request
2020/11/19 19:33:45 [INFO] received CSR
2020/11/19 19:33:45 [INFO] generating key: rsa-2048
2020/11/19 19:33:45 [INFO] encoded CSR
2020/11/19 19:33:45 [INFO] signed certificate with serial number 702889660755572818902097617489801678213146053969



### The Service Account Key Pair
The Kubernetes Controller Manager 는 Service Account token 을 key pair 를 이용하여 생성 및 관리를 한다. 

{

cat > service-account-csr.json <<EOF
{
  "CN": "service-accounts",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "Kubernetes",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  service-account-csr.json | cfssljson -bare service-account

}

[root@localhost ~]# {
> 
> cat > service-account-csr.json <<EOF
> {
>   "CN": "service-accounts",
>   "key": {
>     "algo": "rsa",
>     "size": 2048
>   },
>   "names": [
>     {
>       "C": "US",
>       "L": "Portland",
>       "O": "Kubernetes",
>       "OU": "Kubernetes The Hard Way",
>       "ST": "Oregon"
>     }
>   ]
> }
> EOF
> 
> cfssl gencert \
>   -ca=ca.pem \
>   -ca-key=ca-key.pem \
>   -config=ca-config.json \
>   -profile=kubernetes \
>   service-account-csr.json | cfssljson -bare service-account
> 
> }
2020/11/19 19:36:55 [INFO] generate received request
2020/11/19 19:36:55 [INFO] received CSR
2020/11/19 19:36:55 [INFO] generating key: rsa-2048
2020/11/19 19:36:55 [INFO] encoded CSR
2020/11/19 19:36:55 [INFO] signed certificate with serial number 260962952751094437386584262983354022917431277806
2020/11/19 19:36:55 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").

[root@localhost ~]# ll *.pem
-rw-------. 1 root root 1675 Nov 19 17:11 admin-key.pem
-rw-r--r--. 1 root root 1428 Nov 19 17:11 admin.pem
-rw-------. 1 root root 1679 Nov 19 17:07 ca-key.pem
-rw-r--r--. 1 root root 1318 Nov 19 17:07 ca.pem
-rw-------. 1 root root 1679 Nov 19 18:13 kube-controller-manager-key.pem
-rw-r--r--. 1 root root 1484 Nov 19 18:13 kube-controller-manager.pem
-rw-------. 1 root root 1679 Nov 19 18:15 kube-proxy-key.pem
-rw-r--r--. 1 root root 1452 Nov 19 18:15 kube-proxy.pem
-rw-------. 1 root root 1675 Nov 19 19:33 kubernetes-key.pem
-rw-r--r--. 1 root root 1655 Nov 19 19:33 kubernetes.pem
-rw-------. 1 root root 1675 Nov 19 18:16 kube-scheduler-key.pem
-rw-r--r--. 1 root root 1460 Nov 19 18:16 kube-scheduler.pem
-rw-------. 1 root root 1675 Nov 19 19:36 service-account-key.pem
-rw-r--r--. 1 root root 1440 Nov 19 19:36 service-account.pem
-rw-------. 1 root root 1679 Nov 19 18:09 worker01-key.pem
-rw-r--r--. 1 root root 1484 Nov 19 18:09 worker01.pem
-rw-------. 1 root root 1675 Nov 19 18:09 worker02-key.pem
-rw-r--r--. 1 root root 1484 Nov 19 18:09 worker02.pem
-rw-------. 1 root root 1679 Nov 19 18:09 worker03-key.pem
-rw-r--r--. 1 root root 1484 Nov 19 18:09 worker03.pem


### Distribute the Client and Server Certificates
인증서 배포  (Worker Node)

for instance in worker-0 worker-1 worker-2; do
  gcloud compute scp ca.pem ${instance}-key.pem ${instance}.pem ${instance}:~/
done


인증서 배포 (Master Node)

for instance in controller-0 controller-1 controller-2; do
  gcloud compute scp ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
    service-account-key.pem service-account.pem ${instance}:~/
done


### Hosts 파일 구성

cat >> /etc/hosts << EOF

192.168.1.20    master01
192.168.1.55    master02
192.168.1.56    master03
192.168.1.57    worker01
192.168.1.58    worker02
192.168.1.60    worker03

EOF


THOST=("192.168.1.44" "192.168.1.19" "192.168.1.23" "192.168.1.32")

for ((i=0; i<4; i++)); do

expect <<EOF
spawn ssh root@${THOST[i]} mkdir /root/.ssh/
expect (yes/no)?
send "yes\n"
expect assword
send "!Rlaxogns81\n"
exprct eof
EOF

sleep 2

expect <<EOF
spawn scp .ssh/id_rsa.pub root@${THOST[i]}:~/.ssh/authorized_keys
expect (yes/no)?
send "yes\n"
expect assword
send "!Rlaxogns81\n"
exprct eof
EOF

sleep 2

done


WORKER=("worker01" "worker02" "worker03")
MASTER=("master01" "master02" "master03")

for ((i=0; i<3; i++)); do
  scp ca.pem ${WORKER[i]}-key.pem ${WORKER[i]}.pem ${WORKER[i]}:~/
done

for ((i=0; i<3; i++)); do
  scp ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
    service-account-key.pem service-account.pem ${MASTER[i]}:~/
done




####### Client Authentication Configs

controller manager, kubelet, kube-proxy, and scheduler clients and the admin user. 을 위한 kubeconfig 파일 구성

Kubelet config 파일은 hostname 이 일치해야 한다.



KUBERNETES_PUBLIC_ADDRESS=192.168.1.47

for instance in worker01 worker02 worker03; do
  kubectl config set-cluster kubernetes-the-hard-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=${instance}.kubeconfig

  kubectl config set-credentials system:node:${instance} \
    --client-certificate=${instance}.pem \
    --client-key=${instance}-key.pem \
    --embed-certs=true \
    --kubeconfig=${instance}.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=system:node:${instance} \
    --kubeconfig=${instance}.kubeconfig

  kubectl config use-context default --kubeconfig=${instance}.kubeconfig
done


{
  kubectl config set-cluster kubernetes-the-hard-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config set-credentials system:kube-proxy \
    --client-certificate=kube-proxy.pem \
    --client-key=kube-proxy-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=system:kube-proxy \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
}


{
  kubectl config set-cluster kubernetes-the-hard-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://127.0.0.1:6443 \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config set-credentials system:kube-controller-manager \
    --client-certificate=kube-controller-manager.pem \
    --client-key=kube-controller-manager-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=system:kube-controller-manager \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig
}


{
  kubectl config set-cluster kubernetes-the-hard-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://127.0.0.1:6443 \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config set-credentials system:kube-scheduler \
    --client-certificate=kube-scheduler.pem \
    --client-key=kube-scheduler-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=system:kube-scheduler \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig
}


{
  kubectl config set-cluster kubernetes-the-hard-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://127.0.0.1:6443 \
    --kubeconfig=admin.kubeconfig

  kubectl config set-credentials admin \
    --client-certificate=admin.pem \
    --client-key=admin-key.pem \
    --embed-certs=true \
    --kubeconfig=admin.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=admin \
    --kubeconfig=admin.kubeconfig

  kubectl config use-context default --kubeconfig=admin.kubeconfig
}


for instance in worker-0 worker-1 worker-2; do
  gcloud compute scp ${instance}.kubeconfig kube-proxy.kubeconfig ${instance}:~/
done

for instance in controller-0 controller-1 controller-2; do
  gcloud compute scp admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${instance}:~/
done





for ((i=0; i<3; i++)); do
cat > ${instance[i]}-csr.json <<EOF
{
  "CN": "system:node:${instance[i]}",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "L": "Portland",
      "O": "system:nodes",
      "OU": "Kubernetes The Hard Way",
      "ST": "Oregon"
    }
  ]
}
EOF


ssh root@192.168.1.42 mkdir /root/.ssh/
scp .ssh/id_rsa.pub root@192.168.1.42:~/.ssh/authorized_keys


INTERNAL_IP=("192.168.1.19" "192.168.1.23" "192.168.1.32")
instance=("worker01" "worker02" "worker03")

THOST=("192.168.1.44" "192.168.1.19" "192.168.1.23" "192.168.1.32")
echo $THOST[3]


expect -c 'spawn ssh root@192.168.1.42 mkdir /root/.ssh/ ; expect assword ; send "!Rlaxogns81\n" ; interact'
expect -c 'spawn scp .ssh/id_rsa.pub root@192.168.1.42:~/.ssh/authorized_keys ; expect assword ; send "!Rlaxogns81\n" ; interact'

expect -c 'spawn ssh root@192.168.1.44 mkdir /root/.ssh/ ; expect assword ; send "!Rlaxogns81\n" ; interact'
expect -c 'spawn scp .ssh/id_rsa.pub root@192.168.1.44:~/.ssh/authorized_keys ; expect assword ; send "!Rlaxogns81\n" ; interact'

expect -c 'spawn ssh root@192.168.1.19 mkdir /root/.ssh/ ; expect assword ; send "!Rlaxogns81\n" ; interact'
expect -c 'spawn scp .ssh/id_rsa.pub root@192.168.1.19:~/.ssh/authorized_keys ; expect assword ; send "!Rlaxogns81\n" ; interact'

expect -c 'spawn ssh root@192.168.1.23 mkdir /root/.ssh/ ; expect assword ; send "!Rlaxogns81\n" ; interact'
expect -c 'spawn scp .ssh/id_rsa.pub root@192.168.1.23:~/.ssh/authorized_keys ; expect assword ; send "!Rlaxogns81\n" ; interact'

expect -c 'spawn ssh root@192.168.1.32 mkdir /root/.ssh/ ; expect assword ; send "!Rlaxogns81\n" ; interact'
expect -c 'spawn scp .ssh/id_rsa.pub root@192.168.1.32:~/.ssh/authorized_keys ; expect assword ; send "!Rlaxogns81\n" ; interact'







WORKER=("worker01" "worker02" "worker03")
MASTER=("master01" "master02" "master03")

for ((i=0; i<3; i++)); do
  scp ${WORKER[i]}.kubeconfig kube-proxy.kubeconfig ${WORKER[i]}:~/
done

for ((i=0; i<3; i++)); do
  scp admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${MASTER[i]}:~/
done





################ Generating the Data Encryption Config and Key
Kubernetes 의 Data 를 저장할때 암호화하는 키

ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)

cat > encryption-config.yaml <<EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: ${ENCRYPTION_KEY}
      - identity: {}
EOF

for ((i=0; i<3; i++)); do
 scp encryption-config.yaml ${MASTER[i]}:~/
done


################## Bootstrapping the etcd Cluster

INTERNAL_IP=$(ip addr | grep global | awk '{print $2}' | cut -d/ -f1)
ETCD_NAME=$(hostname -s)
MASTER_NODE=$("192.168.1.21" "192.168.1.55" "192.168.1.56")

### etcd birany download ###
wget "https://github.com/etcd-io/etcd/releases/download/v3.4.10/etcd-v3.4.10-linux-amd64.tar.gz"

### etcd birnay move
tar -xvf etcd-v3.4.10-linux-amd64.tar.gz
sudo mv etcd-v3.4.10-linux-amd64/etcd* /usr/local/bin/

### etcd Service Add
cat <<EOF | sudo tee /etc/systemd/system/etcd.service
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
Type=notify
ExecStart=/usr/local/bin/etcd \\
  --name ${ETCD_NAME} \\
  --cert-file=/etc/etcd/kubernetes.pem \\
  --key-file=/etc/etcd/kubernetes-key.pem \\
  --peer-cert-file=/etc/etcd/kubernetes.pem \\
  --peer-key-file=/etc/etcd/kubernetes-key.pem \\
  --trusted-ca-file=/etc/etcd/ca.pem \\
  --peer-trusted-ca-file=/etc/etcd/ca.pem \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
  --listen-peer-urls https://${INTERNAL_IP}:2380 \\
  --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
  --advertise-client-urls https://${INTERNAL_IP}:2379 \\
  --initial-cluster-token etcd-cluster-0 \\
  --initial-cluster master01=https://${MASTER_NODE[0]}:2380,master02=https://${MASTER_NODE[1]}:2380,master03=https://${MASTER_NODE[2]}:2380 \\
  --initial-cluster-state new \\
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF


systemctl daemon-reload
systemctl enable etcd
systemctl start etcd



ETCDCTL_API=3 \
  etcdctl member list \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca.pem \
  --cert=/etc/etcd/kubernetes.pem \
  --key=/etc/etcd/kubernetes-key.pem




[root@master01 ~]# ETCDCTL_API=3 \
>   etcdctl member list \
>   --endpoints=https://127.0.0.1:2379 \
>   --cacert=/etc/etcd/ca.pem \
>   --cert=/etc/etcd/kubernetes.pem \
>   --key=/etc/etcd/kubernetes-key.pem
15a05845fbd8f2c7, started, master03, https://192.168.1.44:2380, https://192.168.1.44:2379, false
9a92bb99f9fac55e, started, master01, https://192.168.1.26:2380, https://192.168.1.26:2379, false
e10fc861b3b13bc0, started, master02, https://192.168.1.42:2380, https://192.168.1.42:2379, false
[root@master01 ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.




######################   Bootstrapping the Kubernetes Control Plane

sudo mkdir -p /etc/kubernetes/config

wget -q --timestamping \
  "https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kube-apiserver" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kube-controller-manager" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kube-scheduler" \
  "https://storage.googleapis.com/kubernetes-release/release/v1.18.6/bin/linux/amd64/kubectl"


  chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl
  sudo mv kube-apiserver kube-controller-manager kube-scheduler kubectl /usr/local/bin/


  sudo mkdir -p /var/lib/kubernetes/

  sudo mv ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
    service-account-key.pem service-account.pem \
    encryption-config.yaml /var/lib/kubernetes/


cat <<EOF | sudo tee /etc/systemd/system/kube-apiserver.service
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \\
  --advertise-address=${INTERNAL_IP} \\
  --allow-privileged=true \\
  --apiserver-count=3 \\
  --audit-log-maxage=30 \\
  --audit-log-maxbackup=3 \\
  --audit-log-maxsize=100 \\
  --audit-log-path=/var/log/audit.log \\
  --authorization-mode=Node,RBAC \\
  --bind-address=0.0.0.0 \\
  --client-ca-file=/var/lib/kubernetes/ca.pem \\
  --enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\
  --etcd-cafile=/var/lib/kubernetes/ca.pem \\
  --etcd-certfile=/var/lib/kubernetes/kubernetes.pem \\
  --etcd-keyfile=/var/lib/kubernetes/kubernetes-key.pem \\
  --etcd-servers=https://192.168.1.21:2379,https://192.168.1.55:2379,https://192.168.1.56:2379 \\
  --event-ttl=1h \\
  --encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\
  --kubelet-certificate-authority=/var/lib/kubernetes/ca.pem \\
  --kubelet-client-certificate=/var/lib/kubernetes/kubernetes.pem \\
  --kubelet-client-key=/var/lib/kubernetes/kubernetes-key.pem \\
  --kubelet-https=true \\
  --runtime-config=api/all=true \\
  --service-account-key-file=/var/lib/kubernetes/service-account.pem \\
  --service-cluster-ip-range=10.32.0.0/24 \\
  --service-node-port-range=30000-32767 \\
  --tls-cert-file=/var/lib/kubernetes/kubernetes.pem \\
  --tls-private-key-file=/var/lib/kubernetes/kubernetes-key.pem \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF




sudo mv kube-controller-manager.kubeconfig /var/lib/kubernetes/

cat <<EOF | sudo tee /etc/systemd/system/kube-controller-manager.service
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \\
  --bind-address=0.0.0.0 \\
  --cluster-cidr=10.200.0.0/16 \\
  --cluster-name=kubernetes \\
  --cluster-signing-cert-file=/var/lib/kubernetes/ca.pem \\
  --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem \\
  --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\
  --leader-elect=true \\
  --root-ca-file=/var/lib/kubernetes/ca.pem \\
  --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem \\
  --service-cluster-ip-range=10.32.0.0/24 \\
  --use-service-account-credentials=true \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF


sudo mv kube-scheduler.kubeconfig /var/lib/kubernetes/


cat <<EOF | sudo tee /etc/kubernetes/config/kube-scheduler.yaml
apiVersion: kubescheduler.config.k8s.io/v1alpha1
kind: KubeSchedulerConfiguration
clientConnection:
  kubeconfig: "/var/lib/kubernetes/kube-scheduler.kubeconfig"
leaderElection:
  leaderElect: true
EOF

cat <<EOF | sudo tee /etc/systemd/system/kube-scheduler.service
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler \\
  --config=/etc/kubernetes/config/kube-scheduler.yaml \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF


  sudo systemctl daemon-reload
  sudo systemctl enable kube-apiserver kube-controller-manager kube-scheduler
  sudo systemctl start kube-apiserver kube-controller-manager kube-scheduler



### Enable HTTP Health Checks


yum install -y epel-release

yum install -y nginx



cat > kubernetes.default.svc.cluster.local <<EOF
server {
  listen      80;
  server_name kubernetes.default.svc.cluster.local;

  location /healthz {
     proxy_pass                    https://127.0.0.1:6443/healthz;
     proxy_ssl_trusted_certificate /var/lib/kubernetes/ca.pem;
  }
}
EOF

{
  sudo mv kubernetes.default.svc.cluster.local \
    /etc/nginx/conf.d/kubernetes.default.svc.cluster.local
}


sudo systemctl restart nginx

sudo systemctl enable nginx